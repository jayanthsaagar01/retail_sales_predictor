{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retail Forecaster\n",
    "\n",
    "## A Comprehensive System for Retail Sales Forecasting\n",
    "\n",
    "**Date:** May 1, 2025  \n",
    "**Last Updated:** May 1, 2025\n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook provides a detailed explanation of our retail sales prediction system. The application combines weather data and social media sentiment analysis with historical sales figures to create accurate sales forecasts for retailers in India. The entire system is packaged as a Streamlit web application with a user-friendly interface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. System Architecture\n",
    "\n",
    "The application follows a modular architecture with several key components:\n",
    "\n",
    "1. **Web Interface** (Streamlit): Provides user authentication, data upload, visualization, and prediction interfaces\n",
    "2. **Data Processing Pipeline**: Handles data cleaning, feature engineering, and data integration\n",
    "3. **Machine Learning Models**: Uses ensemble techniques to generate accurate predictions\n",
    "4. **Visualization Engine**: Creates intuitive visualizations for data exploration and reporting\n",
    "5. **Database Backend**: SQLite database for storing user data, models, and predictions\n",
    "\n",
    "```\n",
    "                                  +----------------+\n",
    "                                  |                |\n",
    "                                  |   Streamlit    |\n",
    "                                  |   Web Interface|\n",
    "                                  |                |\n",
    "                                  +-------+--------+\n",
    "                                          |\n",
    "                                          v\n",
    "                      +------------------+-------------------+\n",
    "                      |                                      |\n",
    "+ - - - - - - - - - - +     SQLite Database Backend         + - - - - - - - - - - +\n",
    "|                     |                                      |                     |\n",
    "|                     +--+------------------+---------------+                     |\n",
    "|                        |                  |                                      |\n",
    "|                        v                  v                                      v\n",
    "+--------------------+   |  +-------------+   +--------------+    +----------------+\n",
    "|                    |   |  |             |   |              |    |                |\n",
    "| Data Processing    |<--+  | ML Model    |<--+ Visualization|    | External APIs  |\n",
    "| Pipeline           |----->| Training    |--->| Engine      |    | (Weather, etc.)|\n",
    "|                    |      |             |   |              |    |                |\n",
    "+--------------------+      +-------------+   +--------------+    +----------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Sources\n",
    "\n",
    "The system utilizes three primary data sources to build its predictive models:\n",
    "\n",
    "### 2.1 Sales Data\n",
    "\n",
    "Users upload historical sales data in CSV format with the following key fields:\n",
    "- Date: When the sale occurred (YYYY-MM-DD format)\n",
    "- Product_ID: Unique identifier for the product\n",
    "- Category: Product category (e.g., Electronics, Clothing, Food)\n",
    "- Quantity: Number of units sold\n",
    "- Price: Per-unit price in Indian Rupees (₹)\n",
    "- Total_Sales: Total sales amount (Quantity × Price) in ₹\n",
    "\n",
    "### 2.2 Weather Data\n",
    "\n",
    "Weather data is sourced from the OpenWeatherMap API with fallback to synthetic data when API access is unavailable:\n",
    "- Date: Date of weather measurement\n",
    "- Location: Store location (city name)\n",
    "- Temperature: Average daily temperature in °C\n",
    "- Weather_Condition: Description (Sunny, Rainy, Cloudy, etc.)\n",
    "\n",
    "### 2.3 Social Media Sentiment Data\n",
    "\n",
    "The system analyzes social media sentiment related to the brand or product categories:\n",
    "- Date: Date of sentiment analysis\n",
    "- Keywords: Words used for sentiment analysis (brand names, product types)\n",
    "- Sentiment_Score: Numerical score from -1.0 (negative) to 1.0 (positive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Processing Pipeline\n",
    "\n",
    "Our advanced data processing pipeline transforms raw inputs into prediction-ready datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conceptual representation of data processing flow\n",
    "# This is not functional code, but demonstrates the pipeline structure\n",
    "\n",
    "def process_data_pipeline(sales_df, weather_df, sentiment_df):\n",
    "    # Step 1: Clean and preprocess individual datasets\n",
    "    sales_processed = process_sales_data(sales_df)\n",
    "    \n",
    "    # Step 2: Combine datasets\n",
    "    combined_data = combine_datasets(sales_processed, weather_df, sentiment_df)\n",
    "    \n",
    "    # Step 3: Feature engineering\n",
    "    engineered_data = preprocess_data(combined_data)\n",
    "    \n",
    "    return engineered_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Feature Engineering\n",
    "\n",
    "The system implements extensive feature engineering to capture patterns affecting sales:\n",
    "\n",
    "#### 3.1.1 Time-Based Features\n",
    "\n",
    "- Year, Month, Day extraction\n",
    "- Day of week (0-6, where 0 is Monday)\n",
    "- Quarter (1-4)\n",
    "- Day of year (1-366)\n",
    "- Week of year (1-53)\n",
    "- Weekend indicator (1 for weekend, 0 for weekday)\n",
    "- Month start/end indicators\n",
    "- Season (1:Winter, 2:Spring, 3:Summer, 4:Fall)\n",
    "\n",
    "#### 3.1.2 Indian Context-Specific Features\n",
    "\n",
    "The system includes features specifically relevant to Indian retail patterns:\n",
    "\n",
    "- Indian festival indicators (Diwali, Holi, Navratri)\n",
    "- Financial year-end indicator (March in India)\n",
    "\n",
    "#### 3.1.3 Weather Features\n",
    "\n",
    "- Temperature bins (Freezing, Cold, Mild, Warm, Hot)\n",
    "- Weather-day interactions (e.g., Rainy_Weekend)\n",
    "- Weather-season interactions\n",
    "- Rain and snow indicators\n",
    "\n",
    "#### 3.1.4 Sentiment Features\n",
    "\n",
    "- Sentiment bins (Very Negative to Very Positive)\n",
    "- Sentiment lag features (1-day and 7-day)\n",
    "\n",
    "#### 3.1.5 Sales Pattern Features\n",
    "\n",
    "- Sales lag features (1-day, 7-day, 30-day)\n",
    "- Moving averages (7-day, 30-day)\n",
    "- Expanding mean (cumulative average)\n",
    "- Sales volatility (7-day standard deviation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Machine Learning Models\n",
    "\n",
    "The application uses an ensemble approach, combining multiple models to improve prediction accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conceptual representation of ensemble model implementation\n",
    "# Not functional code, but demonstrates the ensemble architecture\n",
    "\n",
    "def create_ensemble_model(X_train, y_train):\n",
    "    # Base models\n",
    "    model1 = RandomForestRegressor(n_estimators=100, n_jobs=-1,\n",
    "                                   max_depth=20, min_samples_split=5,\n",
    "                                   min_samples_leaf=2)\n",
    "    \n",
    "    model2 = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=7,\n",
    "                         min_child_weight=1, subsample=0.8, colsample_bytree=0.8,\n",
    "                         gamma=0)\n",
    "    \n",
    "    model3 = CatBoostRegressor(iterations=100, learning_rate=0.1, depth=6,\n",
    "                              loss_function='RMSE', eval_metric='RMSE',\n",
    "                              random_strength=0.1)\n",
    "    \n",
    "    # Train base models\n",
    "    model1.fit(X_train, y_train)\n",
    "    model2.fit(X_train, y_train)\n",
    "    model3.fit(X_train, y_train)\n",
    "    \n",
    "    # Create ensemble model\n",
    "    ensemble = VotingRegressor([\n",
    "        ('rf', model1),\n",
    "        ('xgb', model2),\n",
    "        ('catboost', model3)\n",
    "    ])\n",
    "    \n",
    "    # Train ensemble model\n",
    "    ensemble.fit(X_train, y_train)\n",
    "    \n",
    "    return ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Model Performance Metrics\n",
    "\n",
    "The system evaluates model performance using multiple metrics to provide a comprehensive assessment:\n",
    "\n",
    "- **R² Score**: Proportion of variance explained (0-1, higher is better)\n",
    "- **Mean Absolute Error (MAE)**: Average absolute difference between predicted and actual sales in ₹\n",
    "- **Mean Squared Error (MSE)**: Average squared error, penalizing larger mistakes more heavily\n",
    "- **Root Mean Squared Error (RMSE)**: Square root of MSE, in the same units as the target variable (₹)\n",
    "- **Mean Absolute Percentage Error (MAPE)**: Average percentage difference between predicted and actual values\n",
    "\n",
    "### 4.2 Model Selection Criteria\n",
    "\n",
    "While the application uses an ensemble by default for optimal performance, different models are better suited for different scenarios:\n",
    "\n",
    "- **Small datasets** (<1000 rows): Linear Regression or SVR\n",
    "- **Medium datasets**: Random Forest\n",
    "- **Large datasets**: XGBoost\n",
    "- **Many categorical features**: CatBoost\n",
    "- **Maximum accuracy needed**: Ensemble (combines all models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualization System\n",
    "\n",
    "The application features intuitive visualizations designed to be easily understandable (\"even a small kid can understand\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example visualization function\n",
    "def plot_sales_forecast(historical_data, predicted_data):\n",
    "    # Set up figure and style\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.style.use('seaborn-whitegrid')\n",
    "    \n",
    "    # Plot settings for readability\n",
    "    plt.rcParams['font.size'] = 12\n",
    "    plt.rcParams['axes.labelsize'] = 14\n",
    "    plt.rcParams['axes.titlesize'] = 16\n",
    "    plt.rcParams['xtick.labelsize'] = 12\n",
    "    plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "    # Custom colors for better differentiation\n",
    "    historical_color = '#1f77b4'  # Blue\n",
    "    prediction_color = '#ff7f0e'  # Orange\n",
    "    confidence_color = '#ffbf80'  # Light orange\n",
    "    \n",
    "    # Format currency for Indian Rupees\n",
    "    def rupee_format(x, pos):\n",
    "        return f'₹{x:,.0f}'\n",
    "    \n",
    "    formatter = FuncFormatter(rupee_format)\n",
    "    \n",
    "    # Add plot elements with clear labels and colors\n",
    "    # Add explanation text for non-technical users\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Key Visualizations\n",
    "\n",
    "The system provides several key visualizations:\n",
    "\n",
    "1. **Sales Trends**: Time-series charts showing sales patterns over time by category\n",
    "2. **Weather Impact**: Visualizations showing how weather conditions affect sales\n",
    "3. **Sentiment Impact**: Charts displaying the relationship between social media sentiment and sales\n",
    "4. **Feature Importance**: Bar charts showing which factors most strongly influence sales predictions\n",
    "5. **Sales Forecast**: Future sales predictions with confidence intervals and clear markings for weekends and special events\n",
    "\n",
    "Each visualization includes:\n",
    "- Clear titles and subtitles\n",
    "- Simplified language for non-technical users\n",
    "- Consistent color schemes\n",
    "- Indian Rupee (₹) formatting\n",
    "- Explanatory text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Database System\n",
    "\n",
    "The application uses a local SQLite database with SQLAlchemy ORM for data persistence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conceptual database schema (not functional code)\n",
    "\n",
    "class User(Base):\n",
    "    __tablename__ = 'users'\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    email = Column(String, unique=True, nullable=False)\n",
    "    password = Column(String, nullable=False)\n",
    "    display_name = Column(String)\n",
    "\n",
    "class SalesData(Base):\n",
    "    __tablename__ = 'sales'\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    date = Column(Date, nullable=False)\n",
    "    user_id = Column(Integer, ForeignKey('users.id'))\n",
    "    product_id = Column(String)\n",
    "    category = Column(String)\n",
    "    quantity = Column(Integer)\n",
    "    price = Column(Float)\n",
    "\n",
    "class WeatherData(Base):\n",
    "    __tablename__ = 'weather'\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    date = Column(Date, nullable=False)\n",
    "    location = Column(String)\n",
    "    user_id = Column(Integer, ForeignKey('users.id'))\n",
    "    temperature = Column(Float)\n",
    "    condition = Column(String)\n",
    "\n",
    "class SentimentData(Base):\n",
    "    __tablename__ = 'sentiment'\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    date = Column(Date, nullable=False)\n",
    "    user_id = Column(Integer, ForeignKey('users.id'))\n",
    "    keywords = Column(String)\n",
    "    sentiment_score = Column(Float)\n",
    "\n",
    "class Model(Base):\n",
    "    __tablename__ = 'models'\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    name = Column(String, nullable=False)\n",
    "    user_id = Column(Integer, ForeignKey('users.id'))\n",
    "    type = Column(String, nullable=False)\n",
    "    metrics = Column(String)  # Serialized metrics\n",
    "    model_data = Column(String)  # Serialized model data\n",
    "    created_at = Column(Date, default=datetime.now)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. User Interface Design\n",
    "\n",
    "The Streamlit web application features a clean, intuitive interface organized into several key pages:\n",
    "\n",
    "### 7.1 Login/Registration Page\n",
    "- Simple email/password authentication\n",
    "- Registration for new users\n",
    "\n",
    "### 7.2 Home Dashboard\n",
    "- Overview of uploaded data\n",
    "- Quick access to key functions\n",
    "- System status indicators\n",
    "\n",
    "### 7.3 Data Upload Page\n",
    "- File upload interface for sales, weather, and sentiment data\n",
    "- Data format guidelines\n",
    "- Data preview and validation\n",
    "\n",
    "### 7.4 Data Visualization Page\n",
    "- Interactive charts and graphs\n",
    "- Filter controls for time periods and categories\n",
    "- Insight generation\n",
    "\n",
    "### 7.5 Sales Prediction Page\n",
    "- Prediction parameter controls\n",
    "- Forecast results with visualizations\n",
    "- Confidence interval display\n",
    "- Model explanation features\n",
    "\n",
    "### 7.6 My Models Page\n",
    "- Access to saved models\n",
    "- Model performance metrics\n",
    "- Model comparison tools\n",
    "\n",
    "### 7.7 About Page\n",
    "- System information\n",
    "- Documentation\n",
    "- Contact details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Improving Model Accuracy\n",
    "\n",
    "To achieve the highest possible model accuracy, the system implements several advanced techniques:\n",
    "\n",
    "### 8.1 Data Quality Improvements\n",
    "- Robust date parsing with multi-stage fallbacks\n",
    "- Outlier detection and handling using IQR method\n",
    "- Missing value imputation strategies\n",
    "\n",
    "### 8.2 Feature Engineering\n",
    "- Polynomial features for capturing non-linear relationships\n",
    "- Interaction features between weather and time variables\n",
    "- Lag features to capture time-series patterns\n",
    "\n",
    "### 8.3 Model Optimization\n",
    "- Ensemble modeling combining multiple algorithms\n",
    "- Hyperparameter optimization\n",
    "- Cross-validation for robust evaluation\n",
    "\n",
    "### 8.4 User Guidance\n",
    "- Clear instructions for data format and quality\n",
    "- Feedback on data quality issues\n",
    "- Suggestions for improving prediction accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Deployment Architecture\n",
    "\n",
    "The application is deployed as a Streamlit web application with the following components:\n",
    "\n",
    "```\n",
    "├── app.py                 # Main Streamlit application entry point\n",
    "├── utils/                 # Utility modules\n",
    "│   ├── __init__.py\n",
    "│   ├── data_processing.py # Data processing functions\n",
    "│   ├── database.py        # Database functions and models\n",
    "│   ├── model.py           # Machine learning models\n",
    "│   ├── sentiment_analysis.py # Sentiment analysis functions\n",
    "│   ├── visualization.py   # Visualization functions\n",
    "│   ├── weather_api.py     # Weather API interface\n",
    "│   └── data/              # Sample data generators\n",
    "│       └── sample_data_generator.py\n",
    "├── .streamlit/            # Streamlit configuration\n",
    "│   └── config.toml        # Server configuration\n",
    "└── sales_prediction.db    # SQLite database file\n",
    "```\n",
    "\n",
    "The application uses the following technology stack:\n",
    "- **Python 3.11**: Core programming language\n",
    "- **Streamlit**: Web framework\n",
    "- **Pandas/NumPy**: Data processing\n",
    "- **Scikit-learn/XGBoost/CatBoost**: Machine learning\n",
    "- **Matplotlib/Seaborn**: Visualization\n",
    "- **SQLAlchemy**: Database ORM\n",
    "- **TextBlob**: Sentiment analysis\n",
    "- **Requests**: HTTP API access"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Future Enhancements\n",
    "\n",
    "The system has several planned future enhancements:\n",
    "\n",
    "1. **Advanced Time Series Models**: Integration of ARIMA, Prophet, and deep learning models\n",
    "2. **Competitor Analysis**: Incorporating competitor data into predictions\n",
    "3. **Economic Indicators**: Adding macroeconomic data like inflation and consumer confidence\n",
    "4. **Multi-Store Support**: Enhanced features for businesses with multiple locations\n",
    "5. **Real-time Updating**: Continuous model updating as new data becomes available\n",
    "6. **Explainable AI**: More detailed model explanations for business users\n",
    "7. **Mobile App Integration**: Companion mobile application for notifications and quick insights\n",
    "8. **Supply Chain Integration**: Connecting predictions to inventory management systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This sales prediction system provides retailers with a powerful tool for forecasting sales based on multiple data sources. By combining historical sales data with weather information and social media sentiment, the system generates highly accurate predictions that can help businesses optimize inventory, staffing, and marketing efforts.\n",
    "\n",
    "The streamlined user interface, intuitive visualizations, and automated ensemble modeling make the system accessible to users without technical expertise, while the advanced feature engineering and model optimization techniques ensure the highest possible prediction accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}